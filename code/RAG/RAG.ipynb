{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1HX3MsOTFUh"
      },
      "source": [
        "# RAG Evaluation ‚Äì Airport Surveillance Knowledge Base\n",
        "\n",
        "## Objective\n",
        "This notebook evaluates the retrieval accuracy of the RAG system\n",
        "built for scenario-aware airport surveillance network orchestration.\n",
        "\n",
        "The evaluation focuses on:\n",
        "- Semantic retrieval quality\n",
        "- Embedding model comparison\n",
        "- Robustness to query variations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-u4IqgbTLd5"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeE4TEilS0Yh"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.api.types import EmbeddingFunction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkVv2DuRWxKZ"
      },
      "outputs": [],
      "source": [
        "from chromadb.api.types import EmbeddingFunction\n",
        "\n",
        "class SentenceTransformerEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, model_name):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def __call__(self, input):\n",
        "        return self.model.encode(input).tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBBa24mlTfaz"
      },
      "outputs": [],
      "source": [
        "TOP_K = 3\n",
        "NUM_QUERIES = 15\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCma2WU4Ucos",
        "outputId": "bca712c6-8562-425d-c0d6-0a3d3d61c452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 300 scenarios\n"
          ]
        }
      ],
      "source": [
        "SCENARIO_FILE = \"scenarios.jsonl\"\n",
        "\n",
        "with open(SCENARIO_FILE, \"r\") as f:\n",
        "    scenarios = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"Loaded {len(scenarios)} scenarios\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY76Me-LVLH2",
        "outputId": "064901d6-0b51-4d62-e670-576e055c3ea3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dict_keys(['metadata', 'structured_facts', 'zone_analysis', 'sla_requirements', 'recommendations', 'text_summary']),\n",
              " {'scenario_id': 204,\n",
              "  'intent': 'failure_recovery',\n",
              "  'time_profile': 'night',\n",
              "  'label': 'failure',\n",
              "  'processed_at': '2026-01-05T17:17:20.954885'})"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scenarios[0].keys(), scenarios[0][\"metadata\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U_l2U1vUpBS",
        "outputId": "1d2b59ea-9dbd-4202-e99a-3fd9c41391c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'scenario_id': 204,\n",
              " 'intent': 'failure_recovery',\n",
              " 'time_profile': 'night',\n",
              " 'label': 'failure',\n",
              " 'processed_at': '2026-01-05T17:17:20.954885'}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scenarios[0][\"metadata\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxJn0LAqcn2N"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "def extract_decision_vector(s):\n",
        "    decision = {\n",
        "        \"fps\": None,\n",
        "        \"bandwidth\": None,\n",
        "        \"processing\": None,\n",
        "        \"latency\": None\n",
        "    }\n",
        "\n",
        "    # 1. Latency from SLA\n",
        "    sla = s.get(\"sla_requirements\", {})\n",
        "    decision[\"latency\"] = sla.get(\"max_latency_ms\")\n",
        "\n",
        "    zone_analysis = s.get(\"zone_analysis\", {})\n",
        "\n",
        "    fps_values = []\n",
        "    bandwidth_values = []\n",
        "    processing_locations = []\n",
        "\n",
        "    for zone in zone_analysis.values():\n",
        "        config = zone.get(\"configuration\", {})\n",
        "        perf = zone.get(\"performance\", {})\n",
        "\n",
        "        if config.get(\"fps\") is not None:\n",
        "            fps_values.append(config[\"fps\"])\n",
        "\n",
        "        if config.get(\"data_rate_mbps\") is not None:\n",
        "            bandwidth_values.append(config[\"data_rate_mbps\"])\n",
        "\n",
        "        if config.get(\"processing_location\"):\n",
        "            processing_locations.append(config[\"processing_location\"])\n",
        "\n",
        "    # 2. Aggregate FPS (median is robust)\n",
        "    if fps_values:\n",
        "        decision[\"fps\"] = int(np.median(fps_values))\n",
        "\n",
        "    # 3. Aggregate bandwidth (sum across zones)\n",
        "    if bandwidth_values:\n",
        "        decision[\"bandwidth\"] = round(sum(bandwidth_values), 2)\n",
        "\n",
        "    # 4. Dominant processing tier\n",
        "    if processing_locations:\n",
        "        decision[\"processing\"] = Counter(processing_locations).most_common(1)[0][0]\n",
        "\n",
        "    return decision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUuTMyYrWM_9"
      },
      "outputs": [],
      "source": [
        "def build_vector_db(model_name):\n",
        "    client = chromadb.Client()\n",
        "    embedding_fn = SentenceTransformerEmbeddingFunction(model_name)\n",
        "\n",
        "    collection = client.create_collection(\n",
        "        name=f\"rag_decision_eval_{model_name}\",\n",
        "        embedding_function=embedding_fn,\n",
        "        get_or_create=True\n",
        "    )\n",
        "\n",
        "    # Clean previous entries\n",
        "    existing = collection.get()\n",
        "    if existing and existing[\"ids\"]:\n",
        "        collection.delete(ids=existing[\"ids\"])\n",
        "\n",
        "    for s in scenarios:\n",
        "        meta = s[\"metadata\"]\n",
        "        dv = extract_decision_vector(s)\n",
        "\n",
        "        retrieval_text = (\n",
        "            f\"Operation: {meta.get('label','normal')}. \"\n",
        "            f\"Time profile: {meta.get('time_profile','unknown')}. \"\n",
        "            f\"Processing tier: {dv['processing']}. \"\n",
        "            f\"Bandwidth: {dv['bandwidth']} Mbps. \"\n",
        "            f\"FPS range: {dv['fps']}. \"\n",
        "            f\"Latency: {dv['latency']} ms. \"\n",
        "            f\"{s['text_summary'][:200]}\"\n",
        "        )\n",
        "\n",
        "        collection.add(\n",
        "            documents=[retrieval_text],\n",
        "            metadatas=[{\"scenario_id\": meta[\"scenario_id\"]}],\n",
        "            ids=[str(meta[\"scenario_id\"])]\n",
        "        )\n",
        "\n",
        "    return collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8y8PZ7xdVbo"
      },
      "outputs": [],
      "source": [
        "def range_overlap(a, b, threshold=0.5):\n",
        "    if not a or not b:\n",
        "        return False\n",
        "    low = max(a[0], b[0])\n",
        "    high = min(a[1], b[1])\n",
        "    return (high - low) / (b[1] - b[0]) >= threshold\n",
        "\n",
        "\n",
        "def close_enough(a, b, tol=0.2):\n",
        "    if a is None or b is None:\n",
        "        return False\n",
        "    return abs(a - b) / b <= tol\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsauGOljuTOU"
      },
      "outputs": [],
      "source": [
        "def fps_compatible(a, b, tol=0.2):\n",
        "    if a is None or b is None:\n",
        "        return False\n",
        "    return abs(a - b) / b <= tol\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc8YIPjhWUim"
      },
      "outputs": [],
      "source": [
        "def decision_compatible(retrieved_s, expected_s):\n",
        "    r = extract_decision_vector(retrieved_s)\n",
        "    e = extract_decision_vector(expected_s)\n",
        "\n",
        "    score = 0\n",
        "    score += fps_compatible(r[\"fps\"], e[\"fps\"])\n",
        "    score += close_enough(r[\"bandwidth\"], e[\"bandwidth\"])\n",
        "    score += r[\"processing\"] == e[\"processing\"]\n",
        "    score += close_enough(r[\"latency\"], e[\"latency\"])\n",
        "\n",
        "    return score >= 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbGqO2Ghdaz9"
      },
      "outputs": [],
      "source": [
        "def generate_queries(s):\n",
        "    meta = s[\"metadata\"]\n",
        "    dv = extract_decision_vector(s)\n",
        "\n",
        "    base = f\"{meta.get('label','normal')} operation during {meta.get('time_profile','normal')}\"\n",
        "    queries = [base]\n",
        "\n",
        "    if dv[\"bandwidth\"] is not None:\n",
        "        queries.append(f\"{base} with limited bandwidth\")\n",
        "\n",
        "    if dv[\"latency\"] is not None:\n",
        "        queries.append(f\"{base} requiring low latency\")\n",
        "\n",
        "    if dv[\"fps\"] is not None:\n",
        "        queries.append(f\"{base} with reduced FPS\")\n",
        "\n",
        "    return queries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TmEMPD9WXMm",
        "outputId": "17bb00e3-bb1a-4a95-d8e2-6518606ce263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'query': 'success operation during evening_rush with limited bandwidth',\n",
              "  'source_id': 34},\n",
              " {'query': 'failure operation during early_morning requiring low latency',\n",
              "  'source_id': 17},\n",
              " {'query': 'success operation during evening_rush with limited bandwidth',\n",
              "  'source_id': 193}]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "queries = []\n",
        "\n",
        "for s in scenarios:\n",
        "    for q in generate_queries(s):\n",
        "        queries.append({\n",
        "            \"query\": q,\n",
        "            \"source_id\": s[\"metadata\"][\"scenario_id\"]\n",
        "        })\n",
        "\n",
        "random.shuffle(queries)\n",
        "queries = queries[:NUM_QUERIES]\n",
        "\n",
        "queries[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7s-iYDbWZ0m"
      },
      "outputs": [],
      "source": [
        "def retrieve_ids(collection, query, k=TOP_K):\n",
        "    result = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=k\n",
        "    )\n",
        "    return [int(i) for i in result[\"ids\"][0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6o3BJr2eijs"
      },
      "outputs": [],
      "source": [
        "models = [\"all-MiniLM-L6-v2\", \"all-mpnet-base-v2\"]\n",
        "results = []\n",
        "\n",
        "for model in models:\n",
        "    collection = build_vector_db(model)\n",
        "\n",
        "    for item in queries:\n",
        "        retrieved_ids = retrieve_ids(collection, item[\"query\"])\n",
        "        expected = next(\n",
        "            s for s in scenarios\n",
        "            if s[\"metadata\"][\"scenario_id\"] == item[\"source_id\"]\n",
        "        )\n",
        "\n",
        "        hits = 0\n",
        "        rr = 0\n",
        "\n",
        "        for rank, rid in enumerate(retrieved_ids, 1):\n",
        "            retrieved_s = next(\n",
        "                s for s in scenarios\n",
        "                if s[\"metadata\"][\"scenario_id\"] == rid\n",
        "            )\n",
        "            if decision_compatible(retrieved_s, expected):\n",
        "                hits += 1\n",
        "                if rr == 0:\n",
        "                    rr = 1 / rank\n",
        "\n",
        "        results.append({\n",
        "            \"model\": model,\n",
        "            \"precision@3\": hits / TOP_K,\n",
        "            \"recall@3\": int(hits > 0),\n",
        "            \"mrr\": rr\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "qSM0UZa6fiG7",
        "outputId": "c74f43f8-77f4-4a7f-e543-80f2218b9980"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"all-mpnet-base-v2\",\n          \"all-MiniLM-L6-v2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision@3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03142696805273545,\n        \"min\": 0.4888888888888889,\n        \"max\": 0.5333333333333333,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.4888888888888889,\n          0.5333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall@3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04714045207910316,\n        \"min\": 0.8,\n        \"max\": 0.8666666666666667,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8666666666666667,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mrr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.039283710065919325,\n        \"min\": 0.6,\n        \"max\": 0.6555555555555556,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6555555555555556,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "summary"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-30ba5dbf-7e8b-41cd-8a2f-b621bf277bbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>precision@3</th>\n",
              "      <th>recall@3</th>\n",
              "      <th>mrr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>all-mpnet-base-v2</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.655556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30ba5dbf-7e8b-41cd-8a2f-b621bf277bbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30ba5dbf-7e8b-41cd-8a2f-b621bf277bbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30ba5dbf-7e8b-41cd-8a2f-b621bf277bbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_cfa248b5-8d2e-47e5-8031-4e9b00efbcb2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cfa248b5-8d2e-47e5-8031-4e9b00efbcb2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               model  precision@3  recall@3       mrr\n",
              "0   all-MiniLM-L6-v2     0.533333  0.800000  0.600000\n",
              "1  all-mpnet-base-v2     0.488889  0.866667  0.655556"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(results)\n",
        "\n",
        "summary = (\n",
        "    df\n",
        "    .groupby(\"model\")[[\"precision@3\", \"recall@3\", \"mrr\"]]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn0f5V7ho-P7",
        "outputId": "749fbe4a-6bf6-490a-8da6-47758d7e08a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Initializing RAG system (this runs once)...\n",
            "‚úÖ RAG system ready.\n",
            "Type your question and press Enter.\n",
            "Type 'exit' or 'quit' to stop.\n",
            "\n",
            "\n",
            "üß† Question:\n",
            "normal daytime operation with bandwidth constraints\n",
            "\n",
            "üîç Retrieving relevant scenarios...\n",
            "\n",
            "--- Result 1 ---\n",
            "Scenario ID : 57\n",
            "Type        : success\n",
            "Time        : night\n",
            "\n",
            "Recommended Configuration:\n",
            "  FPS range       : 10\n",
            "  Bandwidth (Mbps): 392.49\n",
            "  Latency (ms)    : 41.0\n",
            "  Processing tier : edge\n",
            "\n",
            "Explanation:\n",
            "Scenario 57 represents a testing network congestion limits deployment during night operations (8pm-11pm) with reduced traffic. The system operated with 123 active cameras achieving 249.5 Mbps total throughput with an average network delay of 0.269ms. Processing was distributed with 6 zones processed...\n",
            "\n",
            "--- Result 2 ---\n",
            "Scenario ID : 38\n",
            "Type        : success\n",
            "Time        : night\n",
            "\n",
            "Recommended Configuration:\n",
            "  FPS range       : 14\n",
            "  Bandwidth (Mbps): 742.4\n",
            "  Latency (ms)    : 42.0\n",
            "  Processing tier : core\n",
            "\n",
            "Explanation:\n",
            "Scenario 38 represents a testing network congestion limits deployment during night operations (8pm-11pm) with reduced traffic. The system operated with 110 active cameras achieving 467.7 Mbps total throughput with an average network delay of 0.298ms. Processing was distributed with 1 zones processed...\n",
            "\n",
            "--- Result 3 ---\n",
            "Scenario ID : 1\n",
            "Type        : success\n",
            "Time        : night\n",
            "\n",
            "Recommended Configuration:\n",
            "  FPS range       : 10\n",
            "  Bandwidth (Mbps): 424.36\n",
            "  Latency (ms)    : 61.0\n",
            "  Processing tier : edge\n",
            "\n",
            "Explanation:\n",
            "Scenario 1 represents a prioritizing critical security zones deployment during night operations (8pm-11pm) with reduced traffic. The system operated with 115 active cameras achieving 268.0 Mbps total throughput with an average network delay of 0.260ms. Processing was distributed with 4 zones process...\n"
          ]
        }
      ],
      "source": [
        "# ================= INTERACTIVE RAG DEMO =================\n",
        "\n",
        "print(\"üîß Initializing RAG system (this runs once)...\")\n",
        "\n",
        "collection = build_vector_db(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"‚úÖ RAG system ready.\")\n",
        "print(\"Type your question and press Enter.\")\n",
        "print(\"Type 'exit' or 'quit' to stop.\\n\")\n",
        "\n",
        "\n",
        "def show_answer(question, k=3):\n",
        "    result = collection.query(\n",
        "        query_texts=[question],\n",
        "        n_results=k\n",
        "    )\n",
        "\n",
        "    for rank, sid in enumerate(result[\"ids\"][0], start=1):\n",
        "        scenario = next(\n",
        "            s for s in scenarios\n",
        "            if s[\"metadata\"][\"scenario_id\"] == int(sid)\n",
        "        )\n",
        "\n",
        "        meta = scenario[\"metadata\"]\n",
        "        dv = extract_decision_vector(scenario)\n",
        "\n",
        "        print(f\"\\n--- Result {rank} ---\")\n",
        "        print(f\"Scenario ID : {meta['scenario_id']}\")\n",
        "        print(f\"Type        : {meta.get('label','normal')}\")\n",
        "        print(f\"Time        : {meta.get('time_profile','unknown')}\")\n",
        "        print(\"\\nRecommended Configuration:\")\n",
        "        print(f\"  FPS range       : {dv['fps']}\")\n",
        "        print(f\"  Bandwidth (Mbps): {dv['bandwidth']}\")\n",
        "        print(f\"  Latency (ms)    : {dv['latency']}\")\n",
        "        print(f\"  Processing tier : {dv['processing']}\")\n",
        "        print(\"\\nExplanation:\")\n",
        "        print(scenario[\"text_summary\"][:300] + \"...\")\n",
        "\n",
        "\n",
        "# -------- MAIN LOOP --------\n",
        "while True:\n",
        "    question = input(\"\\nAsk a question > \").strip()\n",
        "\n",
        "    if question.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
        "        print(\"\\nüõë Session ended.\")\n",
        "        break\n",
        "\n",
        "    if not question:\n",
        "        print(\"‚ö†Ô∏è Please enter a valid question.\")\n",
        "        continue\n",
        "\n",
        "    print(\"\\nüß† Question:\")\n",
        "    print(question)\n",
        "    print(\"\\nüîç Retrieving relevant scenarios...\")\n",
        "\n",
        "    show_answer(question)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}